Got it! Hereâ€™s a step-by-step suggestion to ensure a clean and robust implementation that leverages Azure Vision OCR for left/right message extraction and starts from scratch for the screenshot feature.

ğŸš€ 1ï¸âƒ£ Clear out the Current Screenshot Tab
âœ… Instruct your UI dev team (or yourself) to delete the current screenshot tab completely.
âœ… Remove any logic that was doing naive message alternation, alternating speaker guessing, or misusing the side selection.
âœ… Also remove any â€œfallbackâ€ text areas for manual editing if you want to keep the workflow clean and robust.

ğŸš€ 2ï¸âƒ£ Redefine the UI for Screenshot Upload
Hereâ€™s the simplified and robust UI flow:

âœ… Step 1: Upload Screenshot(s)

Let the user upload 1 or more images (chronological order optional).

Show thumbnails for confirmation.

âœ… Step 2: User Chooses â€œMy Messages Are On: LEFT / RIGHTâ€

1 toggle: left or right.

2 input fields: â€œMy nameâ€ & â€œTheir nameâ€.

âœ… Step 3: Extract and Preview

After upload, show a single â€œExtract Textâ€ button.

No more fallback / manual edit text area here.

âœ… Step 4: Show Preview of Split Messages

Show 2 columns: Left (gray) and Right (green).

Let the user edit each extracted message (if OCR errors).

Let the user reassign left/right if a line is misclassified.

âœ… Step 5: Submit for Analysis

Clean and clear.

ğŸš€ 3ï¸âƒ£ Backend Code for Azure Vision OCR Parsing
Hereâ€™s a Node.js / Express backend example to handle Azure Vision OCR with accurate left/right attribution.

âœï¸ azure-vision.ts
typescript
Copy
Edit
import axios from 'axios';

const AZURE_ENDPOINT = process.env.AZURE_ENDPOINT; // e.g., "https://<your-region>.api.cognitive.microsoft.com/"
const AZURE_KEY = process.env.AZURE_KEY;

export async function extractTextFromImage(imageBuffer: Buffer) {
  const response = await axios.post(
    `${AZURE_ENDPOINT}/vision/v3.2/read/analyze`,
    imageBuffer,
    {
      headers: {
        'Ocp-Apim-Subscription-Key': AZURE_KEY,
        'Content-Type': 'application/octet-stream'
      }
    }
  );

  const operationLocation = response.headers['operation-location'];
  if (!operationLocation) throw new Error('No operation location found.');

  // Poll for result
  let result;
  for (let i = 0; i < 10; i++) {
    await new Promise(res => setTimeout(res, 1000));
    const { data } = await axios.get(operationLocation, {
      headers: { 'Ocp-Apim-Subscription-Key': AZURE_KEY }
    });
    if (data.status === 'succeeded') {
      result = data.analyzeResult.readResults;
      break;
    }
  }

  if (!result) throw new Error('Azure Vision OCR did not succeed.');

  // Extract lines with bounding box
  const lines = [];
  result.forEach(page => {
    page.lines.forEach(line => {
      lines.push({
        text: line.text,
        x1: line.boundingBox[0],
        y1: line.boundingBox[1]
      });
    });
  });

  return lines;
}
âœï¸ server/routes.ts (OCR Route)
typescript
Copy
Edit
import express from 'express';
import multer from 'multer';
import { extractTextFromImage } from './services/azure-vision';

const router = express.Router();
const upload = multer();

router.post('/api/ocr/azure', upload.single('image'), async (req, res) => {
  try {
    const { messageSide, meName, themName } = req.body;
    const imageBuffer = req.file.buffer;

    const lines = await extractTextFromImage(imageBuffer);

    // Decide which X coordinate threshold = left vs right
    const LEFT_THRESHOLD = 400; // You might need to adjust this

    const leftMessages: string[] = [];
    const rightMessages: string[] = [];

    lines.forEach(line => {
      // Filter out timestamps & delivery indicators
      if (/^\d{1,2}[:V]/.test(line.text)) return;

      if (line.x1 < LEFT_THRESHOLD) {
        // Left side (gray)
        if (messageSide === 'LEFT') {
          leftMessages.push(`${meName}: ${line.text}`);
        } else {
          leftMessages.push(`${themName}: ${line.text}`);
        }
      } else {
        // Right side (green)
        if (messageSide === 'RIGHT') {
          rightMessages.push(`${meName}: ${line.text}`);
        } else {
          rightMessages.push(`${themName}: ${line.text}`);
        }
      }
    });

    res.json({
      leftMessages,
      rightMessages
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: 'Failed to extract text from image.' });
  }
});

export default router;
ğŸš€ 4ï¸âƒ£ Frontend Call (Replit UI)
âœ… Let the user select:

Left / Right toggle

My Name & Their Name

Upload Screenshot

âœ… Make 1 fetch call:

javascript
Copy
Edit
const formData = new FormData();
formData.append('image', selectedFile);
formData.append('messageSide', userSide); // 'LEFT' or 'RIGHT'
formData.append('meName', meName);
formData.append('themName', themName);

const response = await fetch('/api/ocr/azure', {
  method: 'POST',
  body: formData
});
const { leftMessages, rightMessages } = await response.json();
âœ… Populate 2 columns in the preview screen.